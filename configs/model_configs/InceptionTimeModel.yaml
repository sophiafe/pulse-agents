name: "InceptionTimeModel"
pretrained_model_paths: null
params:
  # Basic configuration
  trainer_name: "InceptionTimeTrainer"
  type: "convDL" # Type of model (convML for conventional machine learning, convDL for conventional deep learning and LLM for large language models)
  architecture_type: "CNN" # Architecture type (CNN, RNN)
  mode: "train" # Mode of operation (inference, training)
  save_checkpoint_freq: 0
  verbose: 2 # Controls verbosity of output (0 = silent, 1 = log every 100 batches, 2 = log every batch)

  # Model Architecture
  depth: 12
  kernel_sizes: [1, 3, 5] # Kernel sizes for convolutional layers
  dropout_rate: 0.3

  # Training
  num_epochs: 60
  earlystopping_patience: 10

  # Optimization
  optimizer_name: "adam" # Options: adam, adamw, sgd
  learning_rate: 0.001
  weight_decay: 0.01
  grad_clip_max_norm: 2.0 # max_norm = 1.0 (LSTM, GRU) or 2.0 (CNN, InceptionTime)

  # Scheduler
  scheduler_factor: 0.1
  scheduler_patience: 5
  scheduler_cooldown: 0
  min_lr: 0.000001 # 1e-6
