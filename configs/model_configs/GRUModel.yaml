name: "GRUModel"
pretrained_model_paths: null # "/cluster/project/bmds_lab/sepsis_sophia/pulse/output/output_to_keep/20250525_073320_GRU/Models" # Path to pretrained model (if any)
params:
  # Basic configuration
  trainer_name: "GRUTrainer"
  type: "convDL" # Type of model (convML for conventional machine learning, convDL for conventional deep learning and LLM for large language models)
  architecture_type: "RNN" # Architecture type (CNN, RNN)
  mode: "train" # Mode of operation (inference, training)
  save_checkpoint_freq: 0
  verbose: 2 # Controls verbosity of output (0 = silent, 1 = log every 100 batches, 2 = log every batch)

  # Model Architecture
  hidden_size: 64
  num_layers: 3
  dropout_rate: [0.2, 0.3, 0.3, 0.4, 0.5] # First 3 for GRU layers, last 2 for FC layers
  fc_layers: [64, 16]
  activation: "leaky_relu" # Activation function (relu, leaky_relu, gelu)

  # Training
  num_epochs: 100
  earlystopping_patience: 10

  # Optimization
  optimizer_name: "adam" # Options: adam, adamw, sgd
  learning_rate: 0.001 # 1e-3
  weight_decay: 1e-6
  grad_clip_max_norm: 1.0 # max_norm = 1.0 (LSTM, GRU) or 2.0 (CNN, InceptionTime)

  # Scheduler
  scheduler_factor: 0.1
  scheduler_patience: 5
  scheduler_cooldown: 0
  min_lr: 0.000001 # 1e-6

